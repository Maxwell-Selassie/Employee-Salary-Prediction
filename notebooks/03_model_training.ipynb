{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e24e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow \n",
    "from pathlib import Path\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a59299e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev dataframe successfully loaded with 7500 rows and 38 features\n",
      "Train dataframe successfully loaded with 35000 rows and 38 features\n"
     ]
    }
   ],
   "source": [
    "# load processed train and dev data for modelling\n",
    "def load_data(filepath: str, dataset_type: str) -> pd.DataFrame:\n",
    "    '''\n",
    "        Loads processed data from csv source\n",
    "    \n",
    "        This function loads processed data from csv file\n",
    "        that will be used for modelling\n",
    "        \n",
    "        Args:\n",
    "            filepath: path to processed dataset\n",
    "            dataset_type: whether the dataset is train, dev or test dataframe\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: returns a dataframe containing processed data\n",
    "            \n",
    "        Examples:\n",
    "            >>> df = load_data('data/processed/train_set.csv')\n",
    "                df.head()\n",
    "    '''\n",
    "    filename = Path(filepath)\n",
    "    if not filename.exists():\n",
    "        raise FileNotFoundError(f'File not found! Check filepath and try again later!')\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # check that the df is not empty\n",
    "    if len(df) == 0:\n",
    "        raise ValueError(f'Dataframe cannot be empty!')\n",
    "    \n",
    "    print(f'{dataset_type} dataframe successfully loaded with {df.shape[0]} rows and {df.shape[1]} features')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "TRAIN_DATA_PATH = '../data/processed/train_set.csv'\n",
    "DEV_DATA_PATH = '../data/processed/dev_set.csv'\n",
    "\n",
    "dev_df = load_data(DEV_DATA_PATH, 'Dev')\n",
    "train_df = load_data(TRAIN_DATA_PATH, 'Train')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73832bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All validation passed!\n",
      "All validation passed!\n"
     ]
    }
   ],
   "source": [
    "# perform one last data quality check before modelling\n",
    "def data_quality_checks(df: pd.DataFrame) -> None:\n",
    "    '''\n",
    "        Performs one last data quality check before modelling\n",
    "\n",
    "        Args:\n",
    "            df: pandas' dataframe to be validated\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: if any of the validations fail\n",
    "\n",
    "        Example:\n",
    "            >>> data_quality_checks(df)\n",
    "    '''\n",
    "\n",
    "    missing = df.isnull().sum().sum()\n",
    "    if missing:\n",
    "        raise ValueError(\"The dataset must not contain null values\")\n",
    "    \n",
    "    n_duplicates = df.duplicated().sum()\n",
    "    if n_duplicates != 0:\n",
    "        raise ValueError(\"The dataset must not contain duplicate rows\")\n",
    "\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if len(numerical_cols) != len(df.columns):\n",
    "        raise ValueError(\"All columns in the dataset must be numerical\")\n",
    "\n",
    "    print(\"All validation passed!\")\n",
    "\n",
    "data_quality_checks(train_df)\n",
    "data_quality_checks(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "062b545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data further into features and target set\n",
    "def features_target_split(df: pd.DataFrame, target: str = 'Current_Salary_log') -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    '''\n",
    "        Split the dataset further into features and target splits\n",
    "        \n",
    "        This function takes the given dataframe and splits it\n",
    "        into the feature set and target set for modelling purposes\n",
    "    \n",
    "        Args:\n",
    "            df: pd.DataFrame = Provided dataframe\n",
    "            target: str = Target variable in the given dataframe\n",
    "\n",
    "        Returns:\n",
    "            A tuple of the features and target sets\n",
    "\n",
    "        Examples:\n",
    "            >>> x, y = features_target_split(df, 'Employee_salary')\n",
    "                x.head()\n",
    "                y.head()\n",
    "    '''\n",
    "    y = df[target].copy()\n",
    "    if not isinstance(y, pd.Series):\n",
    "        raise ValueError('The target variable must be a pandas series')\n",
    "    \n",
    "    if len(y) == 0:\n",
    "        raise ValueError(f'The target variable cannot be empty')\n",
    "    \n",
    "    x = df.drop(columns=[target]).copy()\n",
    "    if not isinstance(x, pd.DataFrame):\n",
    "        raise ValueError('The feature set must be a pandas dataframe')\n",
    "    \n",
    "    if len(x) == 0:\n",
    "        raise ValueError(f'The target variable cannot be empty')\n",
    "    \n",
    "    if len(y) != len(x):\n",
    "        raise ValueError('The length of the target variable must be equal to the length of the feature set')\n",
    "\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = features_target_split(train_df)\n",
    "x_dev, y_dev = features_target_split(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00989889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (35000, 37)\n",
      "x_dev: (7500, 37)\n",
      "y_train: (35000,)\n",
      "y_dev: (7500,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train: ', x_train.shape)\n",
    "print(f'x_dev: {x_dev.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print(f'y_dev: {y_dev.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c3641b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, learning_curve\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,root_mean_squared_error,r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ebe138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline models - performing modelling with minimal feature engineering\n",
    "models = {\n",
    "    'Ridge' : Ridge(random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=200, max_depth=6, n_jobs=-1, random_state=1),\n",
    "    'XGBoost': XGBRegressor(),\n",
    "    'LightGBM': LGBMRegressor(random_state=2)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4a974fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: Ridge...\n",
      "Model_name_train : Ridge\n",
      "Mean_squared_error_train : 0.16283124347425945\n",
      "Root_mean_squared_error_train : 0.40352353521728995\n",
      "Mean_absolute_error_train : 0.32872611281472097\n",
      "R^2_score_train : 0.17412199234032788\n",
      "Time_elapsed_train : 0.08465051651000977\n",
      "==================================================\n",
      "Training model: RandomForest...\n",
      "Model_name_train : RandomForest\n",
      "Mean_squared_error_train : 0.15528384174018034\n",
      "Root_mean_squared_error_train : 0.3940607081912384\n",
      "Mean_absolute_error_train : 0.3210497567790834\n",
      "R^2_score_train : 0.21240231848752567\n",
      "Time_elapsed_train : 7.352097272872925\n",
      "==================================================\n",
      "Training model: XGBoost...\n",
      "Model_name_train : XGBoost\n",
      "Mean_squared_error_train : 0.11535355970326377\n",
      "Root_mean_squared_error_train : 0.339637394441872\n",
      "Mean_absolute_error_train : 0.2736790933601069\n",
      "R^2_score_train : 0.4149282040013249\n",
      "Time_elapsed_train : 0.5313794612884521\n",
      "==================================================\n",
      "Training model: LightGBM...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 699\n",
      "[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 10.869476\n",
      "Model_name_train : LightGBM\n",
      "Mean_squared_error_train : 0.145926060828559\n",
      "Root_mean_squared_error_train : 0.38200269741005627\n",
      "Mean_absolute_error_train : 0.31069894027586226\n",
      "R^2_score_train : 0.25986486492829686\n",
      "Time_elapsed_train : 0.35014843940734863\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f'Training model: {model_name}...')\n",
    "    start_time = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "\n",
    "    preds_train = model.predict(x_train)\n",
    "    # preds_dev = model.predict(x_dev)\n",
    "\n",
    "    results = {\n",
    "        'Model_name' : model_name,\n",
    "        'Mean_squared_error' : mean_squared_error(y_train, preds_train),\n",
    "        'Root_mean_squared_error' : root_mean_squared_error(y_train, preds_train),\n",
    "        'Mean_absolute_error' : mean_absolute_error(y_train, preds_train),\n",
    "        'R^2_score' : r2_score(y_train, preds_train),\n",
    "        'Time_elapsed' : time_elapsed\n",
    "    }\n",
    "    \n",
    "    for name, result in results.items():\n",
    "        print(f'{name}_train : {result}')\n",
    "        \n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3f4522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name_train : Ridge\n",
      "cv_score_across_fold_train : [0.39983576 0.40352756 0.4079302  0.39962017 0.40844163]\n",
      "cv_score_mean_train : 0.4038710646820033\n",
      "cv_score_std_train : 0.003790474777318751\n",
      "==================================================\n",
      "model_name_train : RandomForest\n",
      "cv_score_across_fold_train : [0.39590508 0.39885779 0.40323224 0.39622974 0.40148317]\n",
      "cv_score_mean_train : 0.39914160312663644\n",
      "cv_score_std_train : 0.0028723109580029048\n",
      "==================================================\n",
      "model_name_train : XGBoost\n",
      "cv_score_across_fold_train : [0.41266127 0.41454421 0.41647405 0.40909424 0.41444227]\n",
      "cv_score_mean_train : 0.41344321057272293\n",
      "cv_score_std_train : 0.002486816634741162\n",
      "==================================================\n",
      "model_name_train : LightGBM\n",
      "cv_score_across_fold_train : [0.39739636 0.40098042 0.4046927  0.39749862 0.40325354]\n",
      "cv_score_mean_train : 0.4007643259620644\n",
      "cv_score_std_train : 0.002955773327812163\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# cross validation score \n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=9999)\n",
    "\n",
    "for name, model in models.items():\n",
    "    cross_val = cross_val_score(model, x_train, y_train, cv=cv, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "    cv_score = -cross_val\n",
    "    results = {\n",
    "        'model_name' : name,\n",
    "        'cv_score_across_fold' : cv_score,\n",
    "        'cv_score_mean' : cv_score.mean(),\n",
    "        'cv_score_std' : cv_score.std()\n",
    "    }\n",
    "\n",
    "    for name, result in results.items():\n",
    "        print(f'{name}_train : {result}')\n",
    "\n",
    "    print('='*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
